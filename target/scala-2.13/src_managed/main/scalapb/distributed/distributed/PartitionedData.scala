// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package distributed.distributed

@SerialVersionUID(0L)
final case class PartitionedData(
    partitionNumber: _root_.scala.Int = 0,
    sentDataSize: _root_.scala.Int = 0,
    totalDataSize: _root_.scala.Int = 0,
    data: _root_.scala.Seq[_root_.com.google.protobuf.ByteString] = _root_.scala.Seq.empty,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[PartitionedData] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = partitionNumber
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      
      {
        val __value = sentDataSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(2, __value)
        }
      };
      
      {
        val __value = totalDataSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(3, __value)
        }
      };
      data.foreach { __item =>
        val __value = __item
        __size += _root_.com.google.protobuf.CodedOutputStream.computeBytesSize(4, __value)
      }
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = partitionNumber
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      {
        val __v = sentDataSize
        if (__v != 0) {
          _output__.writeInt32(2, __v)
        }
      };
      {
        val __v = totalDataSize
        if (__v != 0) {
          _output__.writeInt32(3, __v)
        }
      };
      data.foreach { __v =>
        val __m = __v
        _output__.writeBytes(4, __m)
      };
      unknownFields.writeTo(_output__)
    }
    def withPartitionNumber(__v: _root_.scala.Int): PartitionedData = copy(partitionNumber = __v)
    def withSentDataSize(__v: _root_.scala.Int): PartitionedData = copy(sentDataSize = __v)
    def withTotalDataSize(__v: _root_.scala.Int): PartitionedData = copy(totalDataSize = __v)
    def clearData = copy(data = _root_.scala.Seq.empty)
    def addData(__vs: _root_.com.google.protobuf.ByteString *): PartitionedData = addAllData(__vs)
    def addAllData(__vs: Iterable[_root_.com.google.protobuf.ByteString]): PartitionedData = copy(data = data ++ __vs)
    def withData(__v: _root_.scala.Seq[_root_.com.google.protobuf.ByteString]): PartitionedData = copy(data = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = partitionNumber
          if (__t != 0) __t else null
        }
        case 2 => {
          val __t = sentDataSize
          if (__t != 0) __t else null
        }
        case 3 => {
          val __t = totalDataSize
          if (__t != 0) __t else null
        }
        case 4 => data
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(partitionNumber)
        case 2 => _root_.scalapb.descriptors.PInt(sentDataSize)
        case 3 => _root_.scalapb.descriptors.PInt(totalDataSize)
        case 4 => _root_.scalapb.descriptors.PRepeated(data.iterator.map(_root_.scalapb.descriptors.PByteString(_)).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: distributed.distributed.PartitionedData.type = distributed.distributed.PartitionedData
    // @@protoc_insertion_point(GeneratedMessage[distributed.PartitionedData])
}

object PartitionedData extends scalapb.GeneratedMessageCompanion[distributed.distributed.PartitionedData] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[distributed.distributed.PartitionedData] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): distributed.distributed.PartitionedData = {
    var __partitionNumber: _root_.scala.Int = 0
    var __sentDataSize: _root_.scala.Int = 0
    var __totalDataSize: _root_.scala.Int = 0
    val __data: _root_.scala.collection.immutable.VectorBuilder[_root_.com.google.protobuf.ByteString] = new _root_.scala.collection.immutable.VectorBuilder[_root_.com.google.protobuf.ByteString]
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __partitionNumber = _input__.readInt32()
        case 16 =>
          __sentDataSize = _input__.readInt32()
        case 24 =>
          __totalDataSize = _input__.readInt32()
        case 34 =>
          __data += _input__.readBytes()
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    distributed.distributed.PartitionedData(
        partitionNumber = __partitionNumber,
        sentDataSize = __sentDataSize,
        totalDataSize = __totalDataSize,
        data = __data.result(),
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[distributed.distributed.PartitionedData] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      distributed.distributed.PartitionedData(
        partitionNumber = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        sentDataSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        totalDataSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        data = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Seq[_root_.com.google.protobuf.ByteString]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = DistributedProto.javaDescriptor.getMessageTypes().get(6)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = DistributedProto.scalaDescriptor.messages(6)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = distributed.distributed.PartitionedData(
    partitionNumber = 0,
    sentDataSize = 0,
    totalDataSize = 0,
    data = _root_.scala.Seq.empty
  )
  implicit class PartitionedDataLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, distributed.distributed.PartitionedData]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, distributed.distributed.PartitionedData](_l) {
    def partitionNumber: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.partitionNumber)((c_, f_) => c_.copy(partitionNumber = f_))
    def sentDataSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.sentDataSize)((c_, f_) => c_.copy(sentDataSize = f_))
    def totalDataSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.totalDataSize)((c_, f_) => c_.copy(totalDataSize = f_))
    def data: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.com.google.protobuf.ByteString]] = field(_.data)((c_, f_) => c_.copy(data = f_))
  }
  final val PARTITIONNUMBER_FIELD_NUMBER = 1
  final val SENTDATASIZE_FIELD_NUMBER = 2
  final val TOTALDATASIZE_FIELD_NUMBER = 3
  final val DATA_FIELD_NUMBER = 4
  def of(
    partitionNumber: _root_.scala.Int,
    sentDataSize: _root_.scala.Int,
    totalDataSize: _root_.scala.Int,
    data: _root_.scala.Seq[_root_.com.google.protobuf.ByteString]
  ): _root_.distributed.distributed.PartitionedData = _root_.distributed.distributed.PartitionedData(
    partitionNumber,
    sentDataSize,
    totalDataSize,
    data
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[distributed.PartitionedData])
}
